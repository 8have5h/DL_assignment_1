{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "norm1 = (0.4914, 0.4822, 0.4465)\n",
    "norm2 = (0.2023, 0.1994, 0.2010)\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), # resize to 256x256 pixels and 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(norm1, norm2)\n",
    "])\n",
    "path = os.getcwd()\n",
    "\n",
    "train_dataset = CustomDataset(root_dir=path + '/train', transform=transform)\n",
    "test_dataset = CustomDataset(root_dir=path + '/test', transform=transform)\n",
    "val_dataset = CustomDataset(root_dir=path + '/val', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def layer_normalization(dim, norm_type):\n",
    "    if norm_type == \"torch_bn\" or norm_type == \"inbuilt\":\n",
    "        return nn.BatchNorm2d(dim)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, downsample=None, norm_type=\"torch_bn\"):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=kernel_size, stride=stride, \n",
    "            padding=1, bias=False\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, out_channels, kernel_size=kernel_size, stride=1, \n",
    "            padding=1, bias=False\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.norm1 = layer_normalization(out_channels, norm_type)\n",
    "        self.norm2 = layer_normalization(out_channels, norm_type)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_residual = x\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            x_residual = self.downsample(x) # downsample the input x to match the output dimensions\n",
    "            \n",
    "        out = self.norm1(self.conv1(x)) # apply the first convolutional layer\n",
    "        out = self.relu(out)\n",
    "        out = self.norm2(self.conv2(out))\n",
    "        \n",
    "        out += x_residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_channels = [16, 32, 64], n_layers = [2, 2, 2], n_classes = 25, norm_type = \"torch_bn\"):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, n_channels[0], kernel_size=3, stride=1, padding=1, bias=False) # 3 input channels for RGB\n",
    "        self.layer_norm = layer_normalization(n_channels[0], norm_type)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.in_channels = n_channels[0]        \n",
    "        self.out_channels = 0\n",
    "        self.features = None\n",
    "                 \n",
    "        layers = {}\n",
    "        for c in range(len(n_channels)):\n",
    "            layer = []\n",
    "            self.out_channels = n_channels[c]\n",
    "            n = n_layers[c]\n",
    "            \n",
    "            for l in range(n):\n",
    "                downsample = None                \n",
    "                if self.in_channels != self.out_channels:\n",
    "                    \"\"\"CHECK KERNEL SIZE HERE\"\"\"\n",
    "                    downsample = nn.Sequential(\n",
    "                        nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, \n",
    "                                  stride=2, padding=1, bias=False), \n",
    "                        layer_normalization(self.out_channels, norm_type)\n",
    "                    )\n",
    "                if c > 0 and l == 0:\n",
    "                    stride = 2\n",
    "                else:\n",
    "                    stride = 1\n",
    "                layer.append(ResidualBlock(self.in_channels, self.out_channels, stride = stride, downsample = downsample, norm_type = norm_type))\n",
    "                if l == 0:\n",
    "                    self.in_channels = self.out_channels       \n",
    "            layers[c+1] = layer\n",
    "            \n",
    "        self.layer1 = nn.Sequential(*layers[1]) # * unpacks the list, so it's like passing each element of the list as an argument\n",
    "        self.layer2 = nn.Sequential(*layers[2])\n",
    "        self.layer3 = nn.Sequential(*layers[3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # do a mean pool\n",
    "        self.avg_pool = nn.AvgPool2d(64)\n",
    "        self.fc = nn.Linear(64, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(\"Input Shape:\", x.shape)\n",
    "        # input convolution\n",
    "        x = self.layer_norm(self.conv(x))\n",
    "        x = self.relu(x)\n",
    "        # print(\"first conv:\", x.shape)\n",
    "        # residual layers\n",
    "        x = self.layer1(x)\n",
    "        # print(\"layer 1 done:\", x.shape)\n",
    "        x = self.layer2(x)\n",
    "        # print(\"layer 2 done:\", x.shape)\n",
    "        x = self.layer3(x)\n",
    "        # print(\"layer 3 done:\", x.shape)\n",
    "        \n",
    "        # average pool\n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        # flatten and fc out\n",
    "        self.features = x.view(-1).detach().cpu()\n",
    "        x = x.view(-1, 64)\n",
    "        x = self.fc(x)\n",
    "        # print(\"fc done:\", x.shape)\n",
    "        return x\n",
    "\n",
    "    def get_features(self):\n",
    "        return self.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4,weight_decay=1e-5, momentum=0.9)\n",
    "schedulers = [\n",
    "    optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1, last_epoch=- 1, verbose=False),\n",
    "    optim.lr_scheduler.CosineAnnealingLR(optimizer, 50, verbose=False)\n",
    "    ]\n",
    "scheduler =  schedulers[1] #Check for self.epochs param\n",
    "criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "\n",
    "# def train(model, device, train_loader, optimizer, epoch):\n",
    "#     model.train()\n",
    "#     for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(data)\n",
    "#         loss = criterion(output, target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(f'Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, Loss {loss.item()}')\n",
    "\n",
    "# def test(model, device, loader):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     targets, preds = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for data, target in loader:\n",
    "#             data, target = data.to(device), target.to(device)\n",
    "#             output = model(data)\n",
    "#             test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "#             pred = output.argmax(dim=1, keepdim=True)\n",
    "#             correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "#             targets.extend(target.view_as(pred).cpu().numpy())\n",
    "#             preds.extend(pred.cpu().numpy())\n",
    "\n",
    "#     test_loss /= len(loader.dataset)\n",
    "#     accuracy = accuracy_score(targets, preds)\n",
    "#     micro_f1 = f1_score(targets, preds, average='micro')\n",
    "#     macro_f1 = f1_score(targets, preds, average='macro')\n",
    "    \n",
    "#     print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}, Micro F1: {micro_f1:.4f}, Macro F1: {macro_f1:.4f}\\n')\n",
    "#     return test_loss, accuracy, micro_f1, macro_f1\n",
    "\n",
    "# for epoch in range(1, 51):\n",
    "#     train(model, device, train_loader, optimizer, epoch)\n",
    "#     test(model, device, train_loader)\n",
    "#     test(model, device, val_loader)\n",
    "#     scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([32, 3, 256, 256])\n",
      "first conv: torch.Size([32, 16, 256, 256])\n",
      "layer 1 done: torch.Size([32, 16, 256, 256])\n",
      "layer 2 done: torch.Size([32, 32, 128, 128])\n",
      "layer 3 done: torch.Size([32, 64, 64, 64])\n",
      "fc done: torch.Size([32, 25])\n",
      "Epoch 1, Batch 0/920, Loss 3.4510180950164795\n",
      "Input Shape: torch.Size([32, 3, 256, 256])\n",
      "first conv: torch.Size([32, 16, 256, 256])\n",
      "layer 1 done: torch.Size([32, 16, 256, 256])\n",
      "layer 2 done: torch.Size([32, 32, 128, 128])\n",
      "layer 3 done: torch.Size([32, 64, 64, 64])\n",
      "fc done: torch.Size([32, 25])\n",
      "Epoch 1, Batch 1/920, Loss 3.4578330516815186\n",
      "Input Shape: torch.Size([32, 3, 256, 256])\n",
      "first conv: torch.Size([32, 16, 256, 256])\n",
      "layer 1 done: torch.Size([32, 16, 256, 256])\n",
      "layer 2 done: torch.Size([32, 32, 128, 128])\n",
      "layer 3 done: torch.Size([32, 64, 64, 64])\n",
      "fc done: torch.Size([32, 25])\n",
      "Epoch 1, Batch 2/920, Loss 3.255673408508301\n",
      "Input Shape: torch.Size([32, 3, 256, 256])\n",
      "first conv: torch.Size([32, 16, 256, 256])\n",
      "layer 1 done: torch.Size([32, 16, 256, 256])\n",
      "layer 2 done: torch.Size([32, 32, 128, 128])\n",
      "layer 3 done: torch.Size([32, 64, 64, 64])\n",
      "fc done: torch.Size([32, 25])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m train_macro_f1s, val_macro_f1s \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m51\u001b[39m):\n\u001b[0;32m---> 10\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     train_loss, train_accuracy, train_micro_f1, train_macro_f1 \u001b[38;5;241m=\u001b[39m test(model, device, train_loader)\n\u001b[1;32m     12\u001b[0m     val_loss, val_accuracy, val_micro_f1, val_macro_f1 \u001b[38;5;241m=\u001b[39m test(model, device, val_loader)\n",
      "Cell \u001b[0;32mIn[32], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"%Y%m%d_%H%M\")\n",
    "def train(args, train_loader, val_loader):\n",
    "\n",
    "    net = ResNet(norm_type = args.norm_type)\n",
    "    print(net)\n",
    "    net = net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "    schedulers = [\n",
    "        optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1, last_epoch=- 1, verbose=False),\n",
    "        optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs, verbose=False)\n",
    "        ]\n",
    "    scheduler =  schedulers[1] #Check for self.epochs param\n",
    "    \n",
    "    loss_tracker = defaultdict(list)\n",
    "    accuracy_tracker = defaultdict(list)    \n",
    "    time_tracker = defaultdict(list)\n",
    "    ft_quantile_tracker = defaultdict(list)\n",
    "\n",
    "    best_accuracy = -1\n",
    "    best_accu_epoch = -1\n",
    "\n",
    "    print(\"\\n\\n---------------------------- MODEL TRAINING BEGINS ----------------------------\")\n",
    "        \n",
    "    t0 = time()\n",
    "    for epoch in range(args.epochs):\n",
    "        print(\"\\n#------------------ Epoch: %d ------------------#\" % epoch)\n",
    "\n",
    "        train_loss = []\n",
    "        correct_pred = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        net.train()\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            # print(idx, len(batch[0]))\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, pred = outputs.max(1)\n",
    "            verdict = torch.eq(pred, labels)\n",
    "            correct_pred += verdict.sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        loss_tracker[\"train\"].append(np.mean(train_loss))\n",
    "        accuracy_tracker[\"train\"].append(round(correct_pred/total_samples*100, 2))\n",
    "\n",
    "        scheduler.step()\n",
    "        print(\"validating...\")\n",
    "        net.eval()\n",
    "        correct_pred = 0\n",
    "        total_samples = 0\n",
    "        val_loss = []\n",
    "        feature_list = []\n",
    "        for idx, batch in enumerate(val_loader):\n",
    "            \n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)        \n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            _, pred = outputs.max(1)\n",
    "            verdict = torch.eq(pred, labels)\n",
    "            correct_pred += verdict.sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "            \n",
    "            feature_list.extend(list(net.get_features().view(-1,1).numpy()))\n",
    "        \n",
    "        loss_tracker[\"val\"].append(np.mean(val_loss))\n",
    "        val_accuracy = round(correct_pred/total_samples*100, 2)\n",
    "        accuracy_tracker[\"val\"].append(val_accuracy)\n",
    "        \n",
    "        ft_quantile_tracker[1].append(np.percentile(feature_list, 1))\n",
    "        ft_quantile_tracker[20].append(np.percentile(feature_list, 20))\n",
    "        ft_quantile_tracker[80].append(np.percentile(feature_list, 80))\n",
    "        ft_quantile_tracker[99].append(np.percentile(feature_list, 99))\n",
    "\n",
    "        t1 = time()\n",
    "\n",
    "        print(\"Epoch: {}, Total Time Elapsed: {}Mins, Train Loss: {}, Train Accuracy: {}%, Validation Loss: {}, Validation Accuracy: {}%\".format(epoch, round((t1-t0)/60,2), loss_tracker[\"train\"][-1], accuracy_tracker[\"train\"][-1], loss_tracker[\"val\"][-1], accuracy_tracker[\"val\"][-1]))\n",
    "        time_tracker['train'].append(round((t1-t0)/60,2))\n",
    "        model_state = {\n",
    "                'accu': val_accuracy,\n",
    "                'epoch': epoch,\n",
    "                'best_accu': best_accuracy,\n",
    "                'best_accu_epoch': best_accu_epoch\n",
    "            }\n",
    "\n",
    "        print(\"Epoch: {}, Saving Model Checkpoint: {}\".format(epoch, now.strftime(\"%d-%m-%y %H:%M\")))\n",
    "        \n",
    "        torch.save(net, os.path.join(args.checkpoint_dir, \"latest_checkpoint_{}.pth\".format(args.norm_type)))\n",
    "        with open(os.path.join(args.checkpoint_dir, \"training_progress_{}.json\".format(args.norm_type)), \"w\") as outfile:\n",
    "            json.dump(model_state, outfile)\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "\n",
    "            best_accuracy = val_accuracy\n",
    "            best_accu_epoch = epoch\n",
    "\n",
    "            model_state = {\n",
    "                'accu': val_accuracy,\n",
    "                'epoch': epoch,\n",
    "                'best_accu': best_accuracy,\n",
    "                'best_accu_epoch': best_accu_epoch\n",
    "            }\n",
    "            \n",
    "            print(\"Best Validation Accuracy Updated = {}%, Last Best = {}%\".format(val_accuracy, best_accuracy))\n",
    "            print(\"Saving Best Model Checkpoint:\", now.strftime(\"%d-%m-%y %H:%M\"))\n",
    "\n",
    "            torch.save(net, os.path.join(args.checkpoint_dir, \"best_val_checkpoint_{}.pth\".format(args.norm_type)))\n",
    "            with open(os.path.join(args.checkpoint_dir, \"training_progress_{}.json\".format(args.norm_type)), \"w\") as outfile:\n",
    "                json.dump(model_state, outfile)\n",
    "\n",
    "\n",
    "        with open(os.path.join(args.result_dir, \"loss_tracker_{}_{}.json\".format(args.norm_type, date_time)), \"w\") as outfile:\n",
    "            json.dump(loss_tracker, outfile)\n",
    "\n",
    "        with open(os.path.join(args.result_dir, \"accuracy_tracker_{}_{}.json\".format(args.norm_type, date_time)), \"w\") as outfile:\n",
    "            json.dump(accuracy_tracker, outfile)\n",
    "\n",
    "        with open(os.path.join(args.result_dir, \"time_tracker_{}_{}.json\".format(args.norm_type, date_time)), \"w\") as outfile:\n",
    "            json.dump(time_tracker, outfile)\n",
    "\n",
    "        with open(os.path.join(args.result_dir, \"ft_quantile_tracker_{}_{}.json\".format(args.norm_type, date_time)), \"w\") as outfile:\n",
    "            json.dump(ft_quantile_tracker, outfile)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(InstanceNorm2d, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(num_features, 1, 1))\n",
    "        self.shift = nn.Parameter(torch.zeros(num_features, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean([2, 3], keepdim=True)\n",
    "        var = x.var([2, 3], keepdim=True, unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        x = x * self.scale + self.shift\n",
    "        return x\n",
    "    \n",
    "\n",
    "class BatchInstanceNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, momentum=0.1):\n",
    "        super(BatchInstanceNorm2d, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(num_features, eps=eps, momentum=momentum)\n",
    "        self.inn = InstanceNorm2d(num_features, eps=eps)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.bn(x) + self.inn(x)\n",
    "\n",
    "class LayerNorm2d(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5):\n",
    "        super(LayerNorm2d, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean([1, 2, 3], keepdim=True)\n",
    "        var = x.var([1, 2, 3], keepdim=True, unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        x = x * self.scale + self.shift\n",
    "        return x\n",
    "\n",
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, num_channels, num_groups=32, eps=1e-5):\n",
    "        super(GroupNorm, self).__init__()\n",
    "        self.num_groups = num_groups\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(1, num_channels, 1, 1))\n",
    "        self.shift = nn.Parameter(torch.zeros(1, num_channels, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        G = self.num_groups\n",
    "        x = x.view(N, G, -1)\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        var = x.var(-1, keepdim=True, unbiased=False)\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        x = x.view(N, C, H, W)\n",
    "        x = x * self.scale + self.shift\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
